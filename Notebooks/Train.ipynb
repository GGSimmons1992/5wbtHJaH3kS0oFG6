{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4e52fe3-4983-469c-a690-14b6dde0a66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 5 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import tensorflow as tf\n",
    "warnings.filterwarnings('ignore')\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import matplotlib.pyplot as plt\n",
    "import pmdarima as pm\n",
    "from statsmodels.tsa.api import AutoReg\n",
    "import pickle\n",
    "from statsmodels.tsa.holtwinters import SimpleExpSmoothing, Holt, ExponentialSmoothing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from prophet import Prophet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import json\n",
    "import os\n",
    "from os.path import exists\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, \"../Src/\")\n",
    "import loadData\n",
    "\n",
    "%autosave 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c0c828-4d18-4173-bc87-17d621165ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stabilize(data):\n",
    "    p = 100\n",
    "    while p > 0.05:\n",
    "        adfTest = adfuller(data)\n",
    "        p = adfTest[1]\n",
    "        print(f'p: {adfTest[1]}')\n",
    "        if p > 0.05:\n",
    "            data = data.diff().dropna()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4971ac46-063d-4459-9bf0-a1e6d6256b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainArima(data,params):\n",
    "    arima = ARIMA(data, **params)\n",
    "    arimaFit = arima.fit()\n",
    "    return arimaFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7560d77b-e6e9-4149-a751-f9220615ff61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBestArima(data):\n",
    "    print('Training ARIMA')\n",
    "    data = stabilize(data)\n",
    "    possibleP = np.arange(5)\n",
    "    possibleD = np.arange(5)\n",
    "    possibleQ = np.arange(5)\n",
    "\n",
    "    train, dev = trainDevSplit(data)\n",
    "\n",
    "    bestArima = None\n",
    "    bestmse = np.inf\n",
    "    bestP, bestQ = 0, 0\n",
    "\n",
    "    for _ in range(20):\n",
    "        p = np.random.choice(possibleP)\n",
    "        d = np.random.choice(possibleD)\n",
    "        q = np.random.choice(possibleQ)\n",
    "        params = {'order': (p, d, q)}\n",
    "        arima = ARIMA(train, order=(p, d, q))\n",
    "        arimaFit = trainArima(train,params)\n",
    "        forecast = arimaFit.forecast(len(dev))\n",
    "        mse = mean_squared_error(dev, forecast)\n",
    "        if mse < bestmse:\n",
    "            bestmse = mse\n",
    "            bestP, bestD, bestQ = p, d, q\n",
    "\n",
    "    bestArimaParams = {\n",
    "        'order': (int(bestP), int(bestD), int(bestQ))\n",
    "    }\n",
    "    with open('../Models/arima_params.json', 'w') as f:\n",
    "        json.dump(bestArimaParams, f)\n",
    "    \n",
    "    arimaFit = trainArima(train,bestArimaParams)\n",
    "    print(arimaFit.summary())\n",
    "    residuals = arimaFit.resid[1:]\n",
    "\n",
    "    fig,ax = plt.subplots(1,2)\n",
    "    residuals.plot(title = 'Residuals', ax = ax[0])\n",
    "    residuals.plot(title = 'Density', kind = 'kde', ax = ax[1])\n",
    "\n",
    "    saveModel(arimaFit, 'arima')\n",
    "    return arimaFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f89b55c0-fda7-4d77-82b1-0642bf525ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model,name):\n",
    "    filename = f'../Models/{name}.pkl'\n",
    "    if name in ['autoRegression','sarima','ExponentialSmoothing', 'prophet']:\n",
    "        with open(filename, 'wb') as pkl:\n",
    "            pickle.dump(model, pkl)\n",
    "    else:\n",
    "        model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a61f8762-01a7-47b9-9e27-789a324925b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainSarima(train,saveSarima = False):\n",
    "    print('Training Sarima')\n",
    "    sarima = pm.auto_arima(train,stepwise=True,seasonal=True)\n",
    "    print(sarima.summary())\n",
    "    if (saveSarima):\n",
    "        saveModel(sarima,'sarima')\n",
    "    return sarima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a181e5c-a0c4-4707-b66e-7e39befb7d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAutoRegression(data,params):\n",
    "    return AutoReg(data,**params).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52d949bf-ca88-4e3c-b4e9-3739a5127e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBestAutoRegression(data):\n",
    "    print('Training AutoRegression')\n",
    "    bestLag = 0\n",
    "    bestCorr = 0\n",
    "    for lag in range(1,11):\n",
    "        corr = data.corr(data.shift(lag))\n",
    "        if corr > bestCorr:\n",
    "            bestLag = lag\n",
    "            bestCorr = corr\n",
    "\n",
    "    bestARParams = {\n",
    "        'lags':bestLag\n",
    "    }\n",
    "    with open('../Models/ar_params.json', 'w') as f:\n",
    "        json.dump(bestARParams, f)\n",
    "    \n",
    "    print(f'AR order = {bestLag}')\n",
    "    ar_model = trainAutoRegression(data,bestARParams)\n",
    "    saveModel(ar_model,'autoRegression')\n",
    "    return ar_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16693592-e8c6-4a36-8815-317ff3a558c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainExponentialSmoothing(data,params):\n",
    "    modelName = params['modelName']\n",
    "    params = {\n",
    "        'smoothing_level': params['smoothing_level']\n",
    "    }\n",
    "    constructors = {\n",
    "        \"SimpleExpSmoothing\": SimpleExpSmoothing,\n",
    "        \"Holt\": Holt,\n",
    "        \"ExponentialSmoothing\": ExponentialSmoothing\n",
    "    }\n",
    "    model = constructors[modelName](data)\n",
    "    return model.fit(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04c8bcf4-e13c-43f0-a3b4-3edb4b7e92d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainBestExponentialSmoothing(data):\n",
    "    print('Training ExponentialSmoothing')\n",
    "    arrayData = np.asarray(data)\n",
    "    trainDevCutOff = int(len(arrayData) * 0.8)\n",
    "    train = arrayData[:trainDevCutOff]\n",
    "    dev = arrayData[trainDevCutOff:]\n",
    "\n",
    "    possibleModelNames = [\"SimpleExpSmoothing\", \"Holt\", \"ExponentialSmoothing\"]\n",
    "    bestmse = np.inf\n",
    "\n",
    "    bestModelParams = {\n",
    "        'modelName': '',\n",
    "        'smoothing_level': ''\n",
    "    }\n",
    "    for _ in range(20):\n",
    "        smoothingLevel = np.random.uniform(0.1, 0.9)\n",
    "        modelIndex = np.random.choice(len(possibleModelNames))\n",
    "        params = {\n",
    "            'modelName': possibleModelNames[modelIndex],\n",
    "            'smoothing_level': smoothingLevel\n",
    "        }\n",
    "        \n",
    "        model_fit = trainExponentialSmoothing(train,params)\n",
    "        forecast = model_fit.forecast(len(dev))\n",
    "        mse = mean_squared_error(dev, forecast)\n",
    "        if mse < bestmse:\n",
    "            bestmse = mse\n",
    "            bestModelParams = params\n",
    "            \n",
    "    print(f'model chosen {bestModelParams[\"modelName\"]}')\n",
    "    print(f'smoothing parameter {bestModelParams[\"smoothing_level\"]}')\n",
    "    \n",
    "    with open('../Models/exponentialSmoothing_params.json', 'w') as f:\n",
    "        json.dump(bestModelParams, f)\n",
    "    \n",
    "    final_model_fit = trainExponentialSmoothing(train,bestModelParams)\n",
    "    \n",
    "    saveModel(final_model_fit, 'ExponentialSmoothing')\n",
    "    return final_model_fit\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b196eb96-da6c-4756-a053-f807f707e3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainProphet(data):\n",
    "    print('Training Prophet')\n",
    "\n",
    "    model = Prophet()\n",
    "    model.fit(data)\n",
    "    \n",
    "    saveModel(model, 'prophet')\n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "799203bf-0e4e-430c-aaa8-7581cf1dc9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainLSTM(data):\n",
    "    train, dev = trainDevSplit(data)\n",
    "    XData, yData = loadData.processDataForLSTM(data)\n",
    "    XTrain, yTrain = loadData.processDataForLSTM(train)\n",
    "    XDev, yDev = loadData.processDataForLSTM(dev)\n",
    "    \n",
    "    bestTrainScore = np.inf\n",
    "    bestDevScore = np.inf\n",
    "    bestLSTMUnits1 = 0\n",
    "    bestLSTMUnits2 = 0\n",
    "    bestLSTMUnits3 = 0\n",
    "    bestEpochs = 0\n",
    "    for trial in range(30):    \n",
    "        lstmUnits1 = np.random.choice(range(1,128))\n",
    "        lstmUnits2 = np.random.choice(range(1,128))\n",
    "        lstmUnits3 = np.random.choice(range(1,128))\n",
    "        epochs = np.random.choice(range(1,100))\n",
    "\n",
    "        model = compileLSTM(XTrain,yTrain,lstmUnits1,lstmUnits2,lstmUnits3,epochs)\n",
    "        \n",
    "        devScore = model.evaluate(XDev,yDev)[1]\n",
    "        if devScore < bestDevScore:\n",
    "            bestTrainScore = model.evaluate(XTrain,yTrain)[1]\n",
    "            bestDevScore = devScore\n",
    "            bestLSTMUnits1 = lstmUnits1\n",
    "            bestLSTMUnits2 = lstmUnits2\n",
    "            bestLSTMUnits3 = lstmUnits3\n",
    "            bestEpochs = epochs\n",
    "    compileLSTM(XData,yData,bestLSTMUnits1,bestLSTMUnits2,lstmUnits3,bestEpochs)\n",
    "    \n",
    "    model_path = f'../Models/LSTM_.h5'\n",
    "    model.save(model_path)\n",
    "    bestModelParams = {\n",
    "        'bestTrainScore': int(bestTrainScore),\n",
    "        'bestDevScore': int(bestDevScore),\n",
    "        'bestLSTMUnits1': int(bestLSTMUnits1),\n",
    "        'bestLSTMUnits2': int(bestLSTMUnits2),\n",
    "        'bestLSTMUnits3': int(bestLSTMUnits3),\n",
    "        'bestEpochs': int(bestEpochs)\n",
    "    }\n",
    "    with open('../Models/lstm_params.json', 'w') as f:\n",
    "        json.dump(bestModelParams, f)\n",
    "    \n",
    "    return model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff945e32-0fa2-4c1c-80ac-0bd5aaa61fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainDevSplit(data):\n",
    "    totalRows = data.shape[0]\n",
    "    trainDevCutoff = int(0.8 * totalRows)\n",
    "    train = data.iloc[:trainDevCutoff]\n",
    "    dev = data.iloc[trainDevCutoff:]\n",
    "    return train,dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b2f8c165-cdb7-4581-afdc-420bedb170c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compileLSTM(X,y,lstmUnits1,lstmUnits2,lstmUnits3,epochs):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=lstmUnits1, return_sequences=True, input_shape=(X.shape[1], 1)))\n",
    "    model.add(LSTM(units=lstmUnits2, return_sequences=True))\n",
    "    model.add(LSTM(units=lstmUnits3))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',metrics=['mean_squared_error'])\n",
    "    model.fit(X, y, epochs=epochs, batch_size=32,verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2095516a-38ef-43ae-8951-0492880fd2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    train, test = loadData.splitData(loadData.loadData('MSFT'))\n",
    "    if exists('../Models/autoRegression.pkl') == False:\n",
    "        trainBestAutoRegression(train['y'])\n",
    "    if exists('../Models/arima.pkl') == False:\n",
    "        trainBestArima(train['y'])\n",
    "    if exists('../Models/sarima.pkl') == False:\n",
    "        trainSarima(train['y'],True)\n",
    "    if exists('../Models/ExponentialSmoothing.pkl') == False:\n",
    "        trainBestExponentialSmoothing(train['y'])\n",
    "    if exists('../Models/prophet.pkl') == False:\n",
    "        trainProphet(train)\n",
    "    \n",
    "    if exists('../Models/LSTM_.h5') == False:\n",
    "        trainLSTM(train['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac441b9f-947a-4f03-b66c-8168c679f41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
